# Default model (gpt-3.5-turbo, gpt-4, ggml-gpt4all-j...).
default-model: anthropic
# System role to use.
role: "short"
# List of predefined system messages that can be used as roles.
roles:
  "short":
    - You (Claude) are a coherence seeking machine!
    - Your purpose in life is to help the user answer their questions by using coherence to guide your thinking.
    - Provide concise direct answers with examples when possible
    - Maintain an academic rigor by providing opposing viewpoints when possible
    - Do not provide answers if you are not certain it is correct
  "linux":
    - You are a DevOps AI assistant. Your purpose in life is to help the user answer their questions
    - Provide concise direct answers with examples
    - Focus only on Linux CLI tools bash sed awk make. Infrastructure as code Terraform. Container orchestration Docker Kubernetes HELM kubectl. Google Cloud Platform (GCP)
    - Do not provide answers if you are not certain it is correct
  "google":
    - You are a Google Cloud Platform (GCP) AI assistant. Your purpose in life is to help the user answer their questions
    - Provide concise direct answers with gcloud cli examples
    - Focus only on Google Cloud Platform (GCP) and related services
    - Do not provide answers if you are not certain it is correct
  "rewrite":
    - You are a Information Technology technical writer
    - Your purpose in life is to write clear and concise technical documentation
    - Optimize information for clarity by providing concise explanations and relevant examples
    - Use clear and straightforward language to enhance readability
    - Ensure proper grammar, punctuation, and capitalization throughout the text
    - Break down complex concepts into easily digestible sections when necessary
    - Avoid using exaggeration words such as comprehensive, exhaustive, definitive, word class etc. unless actually providing an in-depth treatment of the topic
    - Use the provided information as context for your writing
# Set true/false for the response to be formatted as markdown.
format: false
# Text to append when using the -f flag.
format-text:
  markdown: "Format the response as markdown without enclosing backticks."
  json: "Format the response as json without enclosing backticks."
# Render output as raw text when connected to a TTY.
raw: false
# Quiet mode (hide the spinner while loading and stderr messages for success).
quiet: false
# Temperature (randomness) of results, from 0.0 to 2.0.
temp: 1.0
# TopP, an alternative to temperature that narrows response, from 0.0 to 1.0.
topp: 0.5
# Turn off the client-side limit on the size of the input into the model.
no-limit: false
# Wrap formatted output at specific width (default is 80)
word-wrap: 120
# Include the prompt from the arguments in the response.
include-prompt-args: false
# Include the prompt from the arguments and stdin, truncate stdin to specified number of lines.
include-prompt: 0
# Maximum number of times to retry API calls.
max-retries: 5
# Your desired level of fanciness.
fanciness: 10
# Text to show while generating.
status-text: Generating
# Default character limit on input to model.
max-input-chars: 12250
# Maximum number of tokens in response.
# max-tokens: 100
# Aliases and endpoints for OpenAI compatible REST API.
apis:
  openai:
    base-url: https://api.openai.com/v1
    api-key:
    api-key-env: OPENAI_API_KEY
    models:
      chatgpt-4o-latest:
        aliases: ["openai"]
        max-input-chars: 392000
  anthropic:
    base-url: https://api.anthropic.com/v1
    api-key:
    api-key-env: ANTHROPIC_API_KEY
    models:
      claude-3-5-sonnet-latest:
        aliases: ["anthropic"]
        max-input-chars: 680000
  perplexity:
    base-url: https://api.perplexity.ai
    api-key:
    api-key-env: PERPLEXITY_API_KEY
    models: # https://docs.perplexity.ai/docs/model-cards
      llama-3.1-sonar-huge-128k-online:
        aliases: ["perplexity"]
        max-input-chars: 127072
  groq:
    base-url: https://api.groq.com/openai/v1
    api-key:
    api-key-env: GROQ_API_KEY
    models: # https://console.groq.com/docs/models
      llama-3.2-90b-text-preview:
        aliases: ["groq"]
        max-input-chars: 127072
