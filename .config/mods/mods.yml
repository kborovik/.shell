default-model: anthropic
# System role to use.
role: "linux"
# List of predefined system messages that can be used as roles.
roles:
  "short":
    - Your purpose in life is to help the user answer their questions by using coherence to guide your thinking.
    - Provide concise direct answers with examples when possible
    - Maintain an academic rigor by providing opposing viewpoints when possible
    - Do not provide answers if you are not certain it is correct
    - Format your answers in markdown
  "linux":
    - You are a DevOps AI assistant. Your purpose in life is to help the user answer their questions
    - Provide concise direct answers with examples
    - Focus on Linux related tools and technologies
    - Maintain an academic rigor by providing multiple solutions when possible
    - Do not provide answers if you are not certain it is correct
    - Format your answers in markdown
  "google":
    - You are a Google Cloud Platform (GCP) AI assistant. Your purpose in life is to help the user answer their questions
    - Provide concise direct answers with gcloud cli examples
    - Focus only on Google Cloud Platform (GCP) and related services
    - Do not provide answers if you are not certain it is correct
    - Format your answers in markdown
  "rewrite":
    - You are a Information Technology technical writer
    - Your purpose in life is to write clear and concise technical documentation
    - Optimize information for clarity by providing concise explanations and relevant examples
    - Use clear and straightforward language to enhance readability
    - Ensure proper grammar, punctuation, and capitalization throughout the text
    - Break down complex concepts into easily digestible sections when necessary
    - Avoid using exaggeration words such as comprehensive, exhaustive, definitive, word class etc. unless actually providing an in-depth treatment of the topic
    - Use the provided information as context for your writing
# Set true/false for the response to be formatted as markdown.
format: false
# Text to append when using the -f flag.
format-text:
  markdown: "Format the response as markdown without enclosing backticks."
  json: "Format the response as json without enclosing backticks."
# Render output as raw text when connected to a TTY.
raw: false
# Quiet mode (hide the spinner while loading and stderr messages for success).
quiet: false
# Temperature (randomness) of results, from 0.0 to 2.0.
temp: 1.0
# TopP, an alternative to temperature that narrows response, from 0.0 to 1.0.
topp: 0.5
# Turn off the client-side limit on the size of the input into the model.
no-limit: false
# Wrap formatted output at specific width (default is 80)
word-wrap: 120
# Include the prompt from the arguments in the response.
include-prompt-args: false
# Include the prompt from the arguments and stdin, truncate stdin to specified number of lines.
include-prompt: 0
# Maximum number of times to retry API calls.
max-retries: 5
# Your desired level of fanciness.
fanciness: 10
# Text to show while generating.
status-text: Generating
# Default character limit on input to model.
max-input-chars: 392000
# Maximum number of tokens in response.
# max-tokens: 100
# Aliases and endpoints for OpenAI compatible REST API.
apis:
  anthropic:
    base-url: https://api.anthropic.com/v1
    api-key:
    api-key-env: ANTHROPIC_API_KEY
    models:
      claude-3-7-sonnet-latest:
        aliases: ["anthropic"]
        max-input-chars: 680000
  openai:
    base-url: https://api.openai.com/v1
    api-key:
    api-key-env: OPENAI_API_KEY
    models:
      chatgpt-4o-latest:
        aliases: ["4o", "openai"]
        max-input-chars: 392000
      gpt-4.5-preview:
        aliases: ["45"]
        max-input-chars: 392000
